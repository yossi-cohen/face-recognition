{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='center'><img src='images/ou.jpeg' /></div>\n",
    "\n",
    "# Facial Recognition Systems\n",
    "Project proposal for data science workshop  \n",
    "Yossi Cohen: 022446819"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Face recognition is the latest trend when it comes to user authentication.  \n",
    "Facebook has developed the ability to recognize your friends in your photographs.  \n",
    "iPhone X uses Face ID to authenticate users.  \n",
    "Baidu is using face recognition instead of ID cards to allow their employees to enter their offices.  \n",
    "And the list goes on...  \n",
    "\n",
    "My aim in this project is to study the theory behind Face Recognition and implement a simplified version of a face recognition system in Python.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [FaceNet: A Unified Embedding for Face Recognition and Clustering](http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/1A_089.pdf)\n",
    "  - Florian Schroff, Dmitry Kalenichenko, and James Philbin at Google. \n",
    "\n",
    "- [DeepFace: Closing the Gap to Human-Level Performance in Face Verification](https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf) \n",
    "  - Yaniv Taigman, Ming Yang and Marc’Aurelio Ranzato - Facebook AI Research\n",
    "  - Lior Wolf - Tel Aviv University, Israel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Face recognition problems commonly fall into two categories:\n",
    "- **Face Verification** - is this the claimed person? \n",
    "  - Examples:\n",
    "    - At some airports, you can pass through customs by letting a system scan your passport and then verifying that you (the person carrying the passport) are the correct person.\n",
    "    - A mobile phone that unlocks using your face is also using face verification.\n",
    "  - This is a $1:1$ matching problem.\n",
    "- **Face Recognition** - who is this person?\n",
    "    - Example:\n",
    "      - Baidu employees entering the office without needing to otherwise identify themselves. \n",
    "    - This is a $1:K$ matching problem.\n",
    "\n",
    "**Face Recognition** is really a series of several related problems:  \n",
    "\n",
    "1. First, find all faces in a picture\n",
    "2. Second, for each face, be able to identify the person even if the face is turned in a weird direction or in bad lighting.\n",
    "3. Third, pick out unique features of the face that can be used to tell it apart from other people.\n",
    "4. Finally, compare the unique features of that face to all the known people in the database, to determine the person’s name.\n",
    "\n",
    "\n",
    "Before we get into the details of the implementation I want to discuss the details of [FaceNet](http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/1A_089.pdf) which is the network that will be used in this work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FaceNet\n",
    "FaceNet is a neural network that learns a mapping from face images to a compact [Euclidean space](https://en.wikipedia.org/wiki/Euclidean_space) where distances correspond to a measure of face similarity. Hence, the more similar two face images are the lesser the distance between them.  \n",
    "\n",
    "FaceNet learns a neural network that encodes a face image into a vector of 128 numbers.  \n",
    "By comparing two such vectors, you can then determine if two pictures are of the same person.  \n",
    "\n",
    "The embedding is a generic representation for anybody's face.  \n",
    "Unlike other face representations, this embedding has the nice property that a larger distance  \n",
    "between two face embeddings means that the faces are likely not of the same person.   \n",
    "This property makes clustering, similarity detection, and classification tasks easier than other  \n",
    "face recognition techniques where the Euclidean distance between features is not meaningful.\n",
    "\n",
    "### Triplet Loss\n",
    "FaceNet uses a distinct loss method called **Triplet Loss** to calculate loss.  \n",
    "Triplet Loss minimises the distance between an anchor and a positive, images that contain same identity,  \n",
    "and maximises the distance between the anchor and a negative, images that contain different identities.  \n",
    "\n",
    "FaceNet uses a distinct loss method called __*Triplet Loss*__ to calculate loss.  \n",
    "Triplet Loss minimises the distance between an anchor and a positive, images that contain same identity,  \n",
    "and maximises the distance between the anchor and a negative, images that contain different identities.  \n",
    "\n",
    "<p>\n",
    "<font size=6>\n",
    "    $$Loss = \\Sigma_{i=1}^{n}max(0, \\lVert f_i^a - f_i^p \\rVert_2^2 - \\lVert f_i^a - f_i^n \\rVert_2^2 + \\alpha)$$\n",
    "</font>\n",
    "\n",
    "\n",
    "- $f(a)$ refers to the output encoding of the anchor\n",
    "- $f(p)$ refers to the output encoding of the positive\n",
    "- $f(n)$ refers to the output encoding of the negative\n",
    "- $\\alpha$ is a constant used to make sure the network does not try to optimise towards $f(a)-f(p)=f(a)-f(n)=0$\n",
    "\n",
    "<img src='images/triplet-loss.png' />\n",
    "\n",
    "### Siamese Networks\n",
    "FaceNet is a Siamese Network.  \n",
    "A Siamese Network is a type of neural network architecture that learns how to differentiate between two inputs.  \n",
    "This allows them to learn which images are similar and which are not. These images could be contain faces.  \n",
    "\n",
    "Siamese networks consist of two identical neural networks, each with the same exact weights.  \n",
    "First, each network take one of the two input images as input.  \n",
    "Then, the outputs of the last layers of each network are sent to a function that determines whether the images contain the same identity.\n",
    "\n",
    "In FaceNet, this is done by calculating the distance between the two outputs.\n",
    "\n",
    "<img src='images/siamese-networks.jpeg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project data\n",
    "- [LFW dataset -Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/)\n",
    "- Pre trained models\n",
    "- My family pictures folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach and Project Outline\n",
    "\n",
    "In this project, I will implement the following steps of Facial Recognition.  \n",
    "Along the way I will study and present the theory behind the various implementation parts.\n",
    "\n",
    "1. Detect all faces in a picture (using pre-trained models from [dlib](http://blog.dlib.net/2014/02/dlib-186-released-make-your-own-object.html))\n",
    "\n",
    "2. Transform the face for the neural network (using [dlib's real-time pose estimation](http://blog.dlib.net/2014/08/real-time-face-pose-estimation.html) with OpenCV's [affine transformation](https://docs.opencv.org/2.4/doc/tutorials/imgproc/imgtrans/warp_affine/warp_affine.html) to try to make the eyes and bottom lip appear in the same location on each image).\n",
    "\n",
    "3. Use a deep neural network to embed the face on a 128-dimensional unit hypersphere.  \n",
    "\n",
    "4. Use these encodings to perform face verification.  \n",
    "\n",
    "5. Apply clustering or classification techniques to compare the unique features of that face to all the known people in the database, to determine the person’s name.  \n",
    "\n",
    "<img src='images/face-recognition-steps.jpg' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We need to build a pipeline where we solve each step of face recognition separately and pass the result of the current step to the next step.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Finding all the Faces\n",
    "The first step in our pipeline is face detection, so we can try to tell them apart.\n",
    "<br>We will use this step for finding the areas of the image we want to pass on to the next step in our pipeline.\n",
    "\n",
    "<br>We’re going to use a method invented in 2005 called [Histogram of Oriented Gradients](http://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf) — or just HOG for short.\n",
    "<img src='images/face-detection.png' />\n",
    "\n",
    "<font style=\"background-color:yellow;\">**TODO**</font>: Explain details and theoretical background...\n",
    "<img src='images/HOG.png' />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Posing and Projecting Faces\n",
    "<font style=\"background-color:yellow;\">**TODO**</font>: explain landmarks...\n",
    "<img src='images/landmarks.png' />\n",
    "<img src='images/landmarks-2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Encoding Faces\n",
    "\n",
    "<font style=\"background-color:yellow;\">**TODO**</font>: Explain encoding..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Apply clustering /classification to find the person’s name from the encoding\n",
    "<img src='images/compare-encoding.jpeg' />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
